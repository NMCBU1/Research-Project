{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentiment_analysis_spanish import sentiment_analysis\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"consolidado_cantidad_casos_criminalidad_por_anio_mes.csv\", sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daterange(date1, date2):\n",
    "    for n in range(int ((date2 - date1).days)+1):\n",
    "        yield date1 + datetime.timedelta(n)\n",
    "\n",
    "start_dt = datetime.date(2003, 1, 1)\n",
    "end_dt = datetime.date(2008, 12, 1)\n",
    "for dt in daterange(start_dt, end_dt):\n",
    "    df.drop(df[dt.strftime(\"%Y-%m\") == df[\"Fecha_hecho\"]].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums = []\n",
    "dates = []\n",
    "for date in df['Fecha_hecho'].unique():\n",
    "    df2 = pd.read_csv(date + \"_clean.csv\", encoding = \"latin\")\n",
    "    nums.append(df2[\"tweet\"].count())\n",
    "    dates.append(date)\n",
    "df3 = pd.DataFrame({\"dates\": dates,  \"count\": nums})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "424.2875816993464"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3[\"count\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fecha_hecho</th>\n",
       "      <th>Conducta</th>\n",
       "      <th>Cantidad_casos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2009-01</td>\n",
       "      <td>Homicidio</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2009-02</td>\n",
       "      <td>Homicidio</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2009-03</td>\n",
       "      <td>Homicidio</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>2009-04</td>\n",
       "      <td>Homicidio</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>2009-05</td>\n",
       "      <td>Homicidio</td>\n",
       "      <td>209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2021-05</td>\n",
       "      <td>Homicidio</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>2021-06</td>\n",
       "      <td>Homicidio</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>2021-07</td>\n",
       "      <td>Homicidio</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>2021-08</td>\n",
       "      <td>Homicidio</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>2021-09</td>\n",
       "      <td>Homicidio</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Fecha_hecho   Conducta  Cantidad_casos\n",
       "295     2009-01  Homicidio             104\n",
       "296     2009-02  Homicidio             110\n",
       "297     2009-03  Homicidio             113\n",
       "298     2009-04  Homicidio             186\n",
       "299     2009-05  Homicidio             209\n",
       "..          ...        ...             ...\n",
       "443     2021-05  Homicidio              37\n",
       "444     2021-06  Homicidio              44\n",
       "445     2021-07  Homicidio              28\n",
       "446     2021-08  Homicidio              30\n",
       "447     2021-09  Homicidio              30\n",
       "\n",
       "[153 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Conducta\"] == \"Homicidio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Cantidad_casos\"] = pd.to_numeric(df[\"Cantidad_casos\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator CountVectorizer from version 0.23.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/base.py:338: UserWarning: Trying to unpickle estimator MultinomialNB from version 0.23.2 when using version 1.0.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "sentiment = sentiment_analysis.SentimentAnalysisSpanish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.DataFrame({\"length\": range(1,500)})\n",
    "for date in df['Fecha_hecho'].unique():\n",
    "    df4 = pd.read_csv(date + \"_clean.csv\", encoding = \"latin\")\n",
    "    sentiment_list = []\n",
    "    for tweet in df4[\"tweet\"]: \n",
    "        sentiment_list.append(sentiment.sentiment(tweet))\n",
    "    training_set[date] = pd.Series(sentiment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = training_set.fillna(.5)\n",
    "training_set.drop(\"length\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = training_set.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " Homicides = df[df[\"Conducta\"] == \"Homicidio\"][\"Cantidad_casos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>489</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01</th>\n",
       "      <td>7.571231e-06</td>\n",
       "      <td>0.210686</td>\n",
       "      <td>1.078549e-01</td>\n",
       "      <td>0.838480</td>\n",
       "      <td>0.001233</td>\n",
       "      <td>0.093317</td>\n",
       "      <td>0.449385</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.602592</td>\n",
       "      <td>4.872802e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-02</th>\n",
       "      <td>5.365300e-01</td>\n",
       "      <td>0.296440</td>\n",
       "      <td>2.717961e-02</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.952857</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>0.741496</td>\n",
       "      <td>0.297196</td>\n",
       "      <td>4.155509e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-03</th>\n",
       "      <td>2.120335e-01</td>\n",
       "      <td>0.497892</td>\n",
       "      <td>1.252861e-03</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.778197</td>\n",
       "      <td>0.487280</td>\n",
       "      <td>0.437548</td>\n",
       "      <td>0.012598</td>\n",
       "      <td>0.476638</td>\n",
       "      <td>4.108120e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04</th>\n",
       "      <td>2.515014e-01</td>\n",
       "      <td>0.029786</td>\n",
       "      <td>6.934223e-02</td>\n",
       "      <td>0.630631</td>\n",
       "      <td>0.061294</td>\n",
       "      <td>0.487280</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.497892</td>\n",
       "      <td>0.073071</td>\n",
       "      <td>7.918687e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05</th>\n",
       "      <td>3.597197e-03</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>7.928068e-01</td>\n",
       "      <td>0.046609</td>\n",
       "      <td>0.021849</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.314300</td>\n",
       "      <td>0.043096</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>4.309571e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05</th>\n",
       "      <td>4.646954e-05</td>\n",
       "      <td>0.074425</td>\n",
       "      <td>6.874465e-04</td>\n",
       "      <td>0.149023</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.867639</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.010878</td>\n",
       "      <td>6.995389e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>2.000325e-07</td>\n",
       "      <td>0.334302</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.501740</td>\n",
       "      <td>0.009607</td>\n",
       "      <td>3.247803e-02</td>\n",
       "      <td>0.634823</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>7.607403e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-06</th>\n",
       "      <td>4.623355e-01</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>1.009327e-01</td>\n",
       "      <td>0.059407</td>\n",
       "      <td>0.956348</td>\n",
       "      <td>0.999930</td>\n",
       "      <td>0.533377</td>\n",
       "      <td>0.024706</td>\n",
       "      <td>0.067701</td>\n",
       "      <td>6.487025e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>5.159437e-01</td>\n",
       "      <td>0.181532</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.998741</td>\n",
       "      <td>0.028323</td>\n",
       "      <td>3.111479e-08</td>\n",
       "      <td>0.695864</td>\n",
       "      <td>0.183958</td>\n",
       "      <td>2.143078e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07</th>\n",
       "      <td>5.116181e-01</td>\n",
       "      <td>0.372685</td>\n",
       "      <td>4.933628e-01</td>\n",
       "      <td>0.060660</td>\n",
       "      <td>0.173895</td>\n",
       "      <td>0.017999</td>\n",
       "      <td>0.108951</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000911</td>\n",
       "      <td>4.329576e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08</th>\n",
       "      <td>5.286088e-08</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>4.855032e-08</td>\n",
       "      <td>0.515944</td>\n",
       "      <td>0.991556</td>\n",
       "      <td>0.081692</td>\n",
       "      <td>0.342408</td>\n",
       "      <td>0.101418</td>\n",
       "      <td>0.128402</td>\n",
       "      <td>5.568924e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09</th>\n",
       "      <td>4.515859e-02</td>\n",
       "      <td>0.168152</td>\n",
       "      <td>9.455529e-03</td>\n",
       "      <td>0.458453</td>\n",
       "      <td>0.606032</td>\n",
       "      <td>0.339461</td>\n",
       "      <td>0.374758</td>\n",
       "      <td>0.446173</td>\n",
       "      <td>0.924227</td>\n",
       "      <td>1.265873e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361020</td>\n",
       "      <td>1.139461e-07</td>\n",
       "      <td>0.237868</td>\n",
       "      <td>0.012860</td>\n",
       "      <td>0.020328</td>\n",
       "      <td>0.229098</td>\n",
       "      <td>2.105769e-01</td>\n",
       "      <td>0.021037</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>8.035743e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153 rows Ã— 499 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1             2         3         4         5    \\\n",
       "2009-01  7.571231e-06  0.210686  1.078549e-01  0.838480  0.001233  0.093317   \n",
       "2009-02  5.365300e-01  0.296440  2.717961e-02  0.002803  0.004004  0.952857   \n",
       "2009-03  2.120335e-01  0.497892  1.252861e-03  0.000197  0.778197  0.487280   \n",
       "2009-04  2.515014e-01  0.029786  6.934223e-02  0.630631  0.061294  0.487280   \n",
       "2009-05  3.597197e-03  0.002655  7.928068e-01  0.046609  0.021849  0.000121   \n",
       "...               ...       ...           ...       ...       ...       ...   \n",
       "2021-05  4.646954e-05  0.074425  6.874465e-04  0.149023  0.000468  0.867639   \n",
       "2021-06  4.623355e-01  0.999960  1.009327e-01  0.059407  0.956348  0.999930   \n",
       "2021-07  5.116181e-01  0.372685  4.933628e-01  0.060660  0.173895  0.017999   \n",
       "2021-08  5.286088e-08  0.000337  4.855032e-08  0.515944  0.991556  0.081692   \n",
       "2021-09  4.515859e-02  0.168152  9.455529e-03  0.458453  0.606032  0.339461   \n",
       "\n",
       "              6         7         8             9    ...       489  \\\n",
       "2009-01  0.449385  0.000015  0.602592  4.872802e-01  ...  0.500000   \n",
       "2009-02  0.006412  0.741496  0.297196  4.155509e-01  ...  0.500000   \n",
       "2009-03  0.437548  0.012598  0.476638  4.108120e-01  ...  0.500000   \n",
       "2009-04  0.005267  0.497892  0.073071  7.918687e-04  ...  0.500000   \n",
       "2009-05  0.314300  0.043096  0.002655  4.309571e-02  ...  0.500000   \n",
       "...           ...       ...       ...           ...  ...       ...   \n",
       "2021-05  0.374000  0.000118  0.010878  6.995389e-01  ...  0.000279   \n",
       "2021-06  0.533377  0.024706  0.067701  6.487025e-07  ...  0.000218   \n",
       "2021-07  0.108951  0.000011  0.000911  4.329576e-02  ...  0.500000   \n",
       "2021-08  0.342408  0.101418  0.128402  5.568924e-01  ...  0.500000   \n",
       "2021-09  0.374758  0.446173  0.924227  1.265873e-01  ...  0.361020   \n",
       "\n",
       "                  490       491       492       493       494           495  \\\n",
       "2009-01  5.000000e-01  0.500000  0.500000  0.500000  0.500000  5.000000e-01   \n",
       "2009-02  5.000000e-01  0.500000  0.500000  0.500000  0.500000  5.000000e-01   \n",
       "2009-03  5.000000e-01  0.500000  0.500000  0.500000  0.500000  5.000000e-01   \n",
       "2009-04  5.000000e-01  0.500000  0.500000  0.500000  0.500000  5.000000e-01   \n",
       "2009-05  5.000000e-01  0.500000  0.500000  0.500000  0.500000  5.000000e-01   \n",
       "...               ...       ...       ...       ...       ...           ...   \n",
       "2021-05  2.000325e-07  0.334302  0.000008  0.501740  0.009607  3.247803e-02   \n",
       "2021-06  5.159437e-01  0.181532  0.000003  0.998741  0.028323  3.111479e-08   \n",
       "2021-07  5.000000e-01  0.500000  0.500000  0.500000  0.500000  5.000000e-01   \n",
       "2021-08  5.000000e-01  0.500000  0.500000  0.500000  0.500000  5.000000e-01   \n",
       "2021-09  1.139461e-07  0.237868  0.012860  0.020328  0.229098  2.105769e-01   \n",
       "\n",
       "              496       497           498  \n",
       "2009-01  0.500000  0.500000  5.000000e-01  \n",
       "2009-02  0.500000  0.500000  5.000000e-01  \n",
       "2009-03  0.500000  0.500000  5.000000e-01  \n",
       "2009-04  0.500000  0.500000  5.000000e-01  \n",
       "2009-05  0.500000  0.500000  5.000000e-01  \n",
       "...           ...       ...           ...  \n",
       "2021-05  0.634823  0.003104  7.607403e-03  \n",
       "2021-06  0.695864  0.183958  2.143078e-19  \n",
       "2021-07  0.500000  0.500000  5.000000e-01  \n",
       "2021-08  0.500000  0.500000  5.000000e-01  \n",
       "2021-09  0.021037  0.000309  8.035743e-06  \n",
       "\n",
       "[153 rows x 499 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = training_set\n",
    "y = Homicides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train= scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107, 499)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46, 499)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=1000,activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(units=500,activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1/1 [==============================] - 1s 1s/step - loss: 10258.1768 - val_loss: 6839.0454\n",
      "Epoch 2/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 10159.8711 - val_loss: 6833.7026\n",
      "Epoch 3/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 10153.7715 - val_loss: 6833.3647\n",
      "Epoch 4/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 10153.3867 - val_loss: 6833.3208\n",
      "Epoch 5/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3350 - val_loss: 6833.3096\n",
      "Epoch 6/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3232 - val_loss: 6833.3071\n",
      "Epoch 7/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 10153.3203 - val_loss: 6833.3057\n",
      "Epoch 8/400\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 10153.3203 - val_loss: 6833.3052\n",
      "Epoch 9/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 10/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 11/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 12/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 13/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 14/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 15/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 16/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 17/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 18/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 19/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 20/400\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 21/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 22/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 23/400\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 24/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 25/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 26/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 27/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 28/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 29/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 30/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 31/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 32/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 33/400\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 34/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 35/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 36/400\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 37/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 38/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 39/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 40/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 41/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 42/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 43/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 44/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 45/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 46/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 47/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 48/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 49/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 50/400\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 51/400\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 52/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 53/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 54/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 55/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 56/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 57/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 58/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 59/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 60/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 61/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 62/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 63/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 64/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 65/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 66/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 67/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 68/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 69/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 70/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 71/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 72/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 73/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 74/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 75/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 76/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 77/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 78/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 79/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 80/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 81/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 82/400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 83/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 84/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 85/400\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 86/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 87/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 88/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 89/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 90/400\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 91/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 92/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 93/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 94/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 95/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 96/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 97/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 98/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 99/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 100/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 101/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 102/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 103/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 104/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 105/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 106/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 107/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 108/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 109/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 110/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 111/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 112/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 113/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 114/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 115/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 116/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 117/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 118/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 119/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 120/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 121/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 122/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 123/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 124/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 125/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 126/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 127/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 128/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 129/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 130/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 131/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 132/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 133/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 134/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 135/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 136/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 137/400\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 138/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 139/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 140/400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 141/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 142/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 143/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 144/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 145/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 146/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 147/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 148/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 149/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 150/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 151/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 152/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 153/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 154/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 156/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 157/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 158/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 159/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 160/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 161/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 162/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 163/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 164/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 165/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 166/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 167/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 168/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 169/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 170/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 171/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 172/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 173/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 174/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 175/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 176/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 177/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 178/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 179/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 180/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 181/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 182/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 183/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 184/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 185/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 186/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 187/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 188/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 189/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 190/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 191/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 192/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 193/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 194/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 195/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 196/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 197/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 198/400\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 199/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 200/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 201/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 202/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 203/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 204/400\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 205/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 206/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 207/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 208/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 209/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 210/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 211/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 212/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 213/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 214/400\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 215/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 216/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 217/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 218/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 219/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 220/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 221/400\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 222/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 223/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 224/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 225/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 226/400\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 227/400\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 228/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 229/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 230/400\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 231/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 232/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 233/400\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 234/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 235/400\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 236/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 237/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 238/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 239/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 240/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 241/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 242/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 243/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 244/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 245/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 246/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 247/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 248/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 249/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 250/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 251/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 252/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 253/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 254/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 255/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 256/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 257/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 258/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 259/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 260/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 261/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 262/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 263/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 264/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 265/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 266/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 267/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 268/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 269/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 270/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 271/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 272/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 273/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 274/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 275/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 276/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 277/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 278/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 279/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 280/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 281/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 282/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 283/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 284/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 285/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 286/400\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 287/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 288/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 289/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 290/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 291/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 292/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 293/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 294/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 295/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 296/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 297/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 298/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 299/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 300/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 301/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 302/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 303/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 304/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 305/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 306/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 307/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 308/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 309/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 310/400\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 311/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 312/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 313/400\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 314/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 315/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 316/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 317/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 318/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 319/400\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 320/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 321/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 322/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 323/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 324/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 325/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 326/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 327/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 328/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 329/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 330/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 331/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 332/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 333/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 334/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 335/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 336/400\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 337/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 338/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 339/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 340/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 341/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 342/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 343/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 344/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 345/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 346/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 347/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 348/400\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 349/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 350/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 351/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 352/400\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 353/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 354/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 355/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 356/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 357/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 358/400\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 359/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 360/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 361/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 362/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 363/400\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 364/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 365/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 366/400\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 367/400\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 368/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 369/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 370/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 371/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 372/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 373/400\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 374/400\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 375/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 376/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 377/400\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 378/400\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 379/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 380/400\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 381/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 382/400\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 383/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 384/400\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 385/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 386/400\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 387/400\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 388/400\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 389/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 390/400\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 391/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 392/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 393/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 394/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 395/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 396/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 397/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 398/400\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 399/400\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 10153.3174 - val_loss: 6833.3042\n",
      "Epoch 400/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 10153.3174 - val_loss: 6833.3042\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a5eca6850>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train.values,\n",
    "          validation_data=(X_test,y_test.values),\n",
    "          batch_size=128,epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a610c6710>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAZvElEQVR4nO3df5BU5b3n8fcHGEGCRsABgTGCuSgqbIhpkdy7mdyo4YdrRI1JxhglrCWJv3UrrlpWotcfm8T8cMsqF5dcUUyMQtSsbFQMV12JVVFpcPilESaoOEBgECTuEhSG7/7Rz2gHekZ6eqZ75s7nVdXVp5/znNPffpjhM+c5p7sVEZiZWc/Wq9IFmJlZ5TkMzMzMYWBmZg4DMzPDYWBmZkCfShfQXocffniMHDmy0mWYmXUbS5cu3RoR1YXWddswGDlyJNlsttJlmJl1G5Leam2dp4nMzMxhYGZmDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzN6WBg07w3ufq6BxWuaKl2KmVmX0qPCoHcv8T+f/zO/f/UvlS7FzKxL6VFhAHDU4E+wftvfKl2GmVmX0uPC4FOD+vP2tp2VLsPMrEvpeWEwuD+N23fSvNdf92lm1qLnhcGg/uxuDjbt8FSRmVmLbvuppe111KD+ANz2u9cYV/NJAHpJ9BJIlazMzOzjHVzVmws+P7LD99vjwuBzIwdy2nFDWbj6Lyxc7auKzKx7OXxAX4dBR+jbpzf/Oj3Dnua9NEcQARGwN3wOwcy6vs6awehxYdCiT+9ePffFm5nto8edQDYzs/05DMzMzGFgZmYHEAaS5kjaImlVXtsgSYskrU33A1O7JN0lqUHSCkkn5m0zPfVfK2l6XvvnJK1M29wl+QJPM7NyO5Ajg/uBKfu0XQ88ExGjgWfSY4CpwOh0mwnMglx4ADcBJwMTgJtaAiT1mZm33b7PZWZmnexjwyAiFgPb9mmeBsxNy3OBs/LaH4icF4HDJA0DJgOLImJbRGwHFgFT0rpDI+KPERHAA3n7MjOzMmnvOYOhEbEJIN0PSe0jgLfz+jWmtrbaGwu0FyRppqSspGxTk7+TwMyso3T0CeRC8/3RjvaCImJ2RGQiIlNdXd3OEs3MbF/tDYPNaYqHdL8ltTcCR+b1qwE2fkx7TYF2MzMro/aGwQKg5Yqg6cDjee0XpquKJgI70jTS08AkSQPTieNJwNNp3XuSJqariC7M25eZmZXJx34ig6SHgH8GDpfUSO6qoB8B8yVdBKwHvpa6PwmcDjQAO4EZABGxTdKtwJLU75aIaDkpfQm5K5YOBp5KNzMzKyNFN/2AtkwmE9lsttJlmJl1G5KWRkSm0Dq/A9nMzBwGZmbmMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZkaJYSDpKkmrJK2WdHVqu1nSBkn16XZ6Xv8bJDVIel3S5Lz2KamtQdL1pdRkZmbF69PeDSWNBS4GJgAfAAslPZFW3xkRP92n//FAHXACMBz4N0nHpNV3A18GGoElkhZExKvtrc3MzIrT7jAAjgNejIidAJKeB85uo/804OGIeB94Q1IDuSABaIiIdWk/D6e+DgMzszIpZZpoFVArabCk/sDpwJFp3eWSVkiaI2lgahsBvJ23fWNqa619P5JmSspKyjY1NZVQupmZ5Wt3GETEa8CPgUXAQmA5sAeYBXwaGA9sAn6WNlGh3bTRXug5Z0dEJiIy1dXV7S3dzMz2UdIJ5Ii4NyJOjIhaYBuwNiI2R0RzROwFfsFHU0GNfHTkAFADbGyj3czMyqTUq4mGpPtPAecAD0kaltflbHLTSQALgDpJfSWNAkYDLwNLgNGSRkk6iNxJ5gWl1GVmZsUp5QQywKOSBgO7gcsiYrukX0oaT26q503gOwARsVrSfHInhvek/s0Aki4HngZ6A3MiYnWJdZmZWREUUXB6vsvLZDKRzWYrXYaZWbchaWlEZAqt8zuQzczMYWBmZg4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRkOAzMzw2FgZmY4DMzMDIeBmZnhMDAzMxwGZmaGw8DMzHAYmJkZDgMzM8NhYGZmlBgGkq6StErSaklXp7ZBkhZJWpvuB6Z2SbpLUoOkFZJOzNvP9NR/raTppb0kMzMrVrvDQNJY4GJgAvAZ4AxJo4HrgWciYjTwTHoMMBUYnW4zgVlpP4OAm4CT075uagkQMzMrj1KODI4DXoyInRGxB3geOBuYBsxNfeYCZ6XlacADkfMicJikYcBkYFFEbIuI7cAiYEoJdZmZWZFKCYNVQK2kwZL6A6cDRwJDI2ITQLofkvqPAN7O274xtbXWvh9JMyVlJWWbmppKKN3MzPK1Owwi4jXgx+T+kl8ILAf2tLGJCu2mjfZCzzk7IjIRkamuri6yYjMza01JJ5Aj4t6IODEiaoFtwFpgc5r+Id1vSd0byR05tKgBNrbRbmZmZVLq1URD0v2ngHOAh4AFQMsVQdOBx9PyAuDCdFXRRGBHmkZ6GpgkaWA6cTwptZmZWZn0KXH7RyUNBnYDl0XEdkk/AuZLughYD3wt9X2S3HmFBmAnMAMgIrZJuhVYkvrdEhHbSqzLzMyKoIiC0/NdXiaTiWw2W+kyzMy6DUlLIyJTaJ3fgWxmZg4DMzNzGJiZGaWfQDYzK5vdu3fT2NjIrl27Kl1Kl9avXz9qamqoqqo64G0cBmbWbTQ2NnLIIYcwcuRIpELvV7WI4J133qGxsZFRo0Yd8HaeJjKzbmPXrl0MHjzYQdAGSQwePLjooyeHgZl1Kw6Cj9eeMXIYmJmZw8DMrBgDBgyodAmdwmFgZmYOAzOz9ogIrr32WsaOHcu4ceOYN28eAJs2baK2tpbx48czduxY/vCHP9Dc3My3v/3tD/veeeedFa5+f7601My6pX/536t5deNfO3Sfxw8/lJu+csIB9X3ssceor69n+fLlbN26lZNOOona2lp+/etfM3nyZG688Uaam5vZuXMn9fX1bNiwgVWrVgHw7rvvdmjdHcFHBmZm7fDCCy9w3nnn0bt3b4YOHcoXv/hFlixZwkknncR9993HzTffzMqVKznkkEM4+uijWbduHVdccQULFy7k0EMPrXT5+/GRgZl1Swf6F3xnae0Tn2tra1m8eDFPPPEEF1xwAddeey0XXnghy5cv5+mnn+buu+9m/vz5zJkzp8wVt81HBmZm7VBbW8u8efNobm6mqamJxYsXM2HCBN566y2GDBnCxRdfzEUXXcSyZcvYunUre/fu5atf/Sq33nory5Ytq3T5+/GRgZlZO5x99tn88Y9/5DOf+QySuOOOOzjiiCOYO3cuP/nJT6iqqmLAgAE88MADbNiwgRkzZrB3714AfvjDH1a4+v35y23MrNt47bXXOO644ypdRrdQaKz85TZmZtYmh4GZmTkMzMysxDCQdI2k1ZJWSXpIUj9J90t6Q1J9uo1PfSXpLkkNklZIOjFvP9MlrU236aW+KDMzK067ryaSNAK4Ejg+Iv4maT5Ql1ZfGxGP7LPJVGB0up0MzAJOljQIuAnIAAEslbQgIra3tzYzMytOqdNEfYCDJfUB+gMb2+g7DXggcl4EDpM0DJgMLIqIbSkAFgFTSqzLzMyK0O4wiIgNwE+B9cAmYEdE/D6tvj1NBd0pqW9qGwG8nbeLxtTWWvt+JM2UlJWUbWpqam/pZma2j3aHgaSB5P7aHwUMBz4h6VvADcAY4CRgEHBdyyYFdhNttO/fGDE7IjIRkamurm5v6WZmZdHWdx+8+eabjB07tozVtK2UaaLTgDcioikidgOPAf8YEZvSVND7wH3AhNS/ETgyb/sactNKrbWbmVmZlPJxFOuBiZL6A38DTgWykoZFxCblvoTzLGBV6r8AuFzSw+ROIO9I/Z4G/ls60gCYRO7owsysdU9dD39Z2bH7PGIcTP1Rq6uvu+46jjrqKC699FIAbr75ZiSxePFitm/fzu7du7ntttuYNm1aUU+7a9cuLrnkErLZLH369OHnP/85X/rSl1i9ejUzZszggw8+YO/evTz66KMMHz6cr3/96zQ2NtLc3Mz3v/99vvGNb5T0sqGEMIiIlyQ9AiwD9gCvALOBpyRVk5v+qQe+mzZ5EjgdaAB2AjPSfrZJuhVYkvrdEhHb2luXmVlnqaur4+qrr/4wDObPn8/ChQu55pprOPTQQ9m6dSsTJ07kzDPPLOpL6e+++24AVq5cyZ/+9CcmTZrEmjVruOeee7jqqqs4//zz+eCDD2hububJJ59k+PDhPPHEEwDs2LGjQ15bSR9UFxE3kbssNN8prfQN4LJW1s0ButbnuZpZ19bGX/Cd5bOf/Sxbtmxh48aNNDU1MXDgQIYNG8Y111zD4sWL6dWrFxs2bGDz5s0cccQRB7zfF154gSuuuAKAMWPGcNRRR7FmzRo+//nPc/vtt9PY2Mg555zD6NGjGTduHN/73ve47rrrOOOMM/jCF77QIa/N70A2MyvCueeeyyOPPMK8efOoq6vjwQcfpKmpiaVLl1JfX8/QoUPZtWtXUfts7QNDv/nNb7JgwQIOPvhgJk+ezLPPPssxxxzD0qVLGTduHDfccAO33HJLR7wsf4S1mVkx6urquPjii9m6dSvPP/888+fPZ8iQIVRVVfHcc8/x1ltvFb3P2tpaHnzwQU455RTWrFnD+vXrOfbYY1m3bh1HH300V155JevWrWPFihWMGTOGQYMG8a1vfYsBAwZw//33d8jrchiYmRXhhBNO4L333mPEiBEMGzaM888/n6985StkMhnGjx/PmDFjit7npZdeyne/+13GjRtHnz59uP/+++nbty/z5s3jV7/6FVVVVRxxxBH84Ac/YMmSJVx77bX06tWLqqoqZs2a1SGvy99nYGbdhr/P4MD5+wzMzKxoniYyM+tEK1eu5IILLvi7tr59+/LSSy9VqKLCHAZm1q1ERFHX8FfauHHjqK+vL+tztmf639NEZtZt9OvXj3feeadd/9n1FBHBO++8Q79+/YrazkcGZtZt1NTU0NjYiD+1uG39+vWjpqamqG0cBmbWbVRVVTFq1KhKl/HvkqeJzMzMYWBmZg4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMKDEMJF0jabWkVZIektRP0ihJL0laK2mepINS377pcUNaPzJvPzek9tclTS7tJZmZWbHaHQaSRgBXApmIGAv0BuqAHwN3RsRoYDtwUdrkImB7RPwDcGfqh6Tj03YnAFOA/yGpd3vrMjOz4pU6TdQHOFhSH6A/sAk4BXgkrZ8LnJWWp6XHpPWnKvc5tNOAhyPi/Yh4A2gAJpRYl5mZFaHdYRARG4CfAuvJhcAOYCnwbkTsSd0agRFpeQTwdtp2T+o/OL+9wDZmZlYGpUwTDST3V/0oYDjwCWBqga4tHzxe6Nsooo32Qs85U1JWUtYfYWtm1nFKmSY6DXgjIpoiYjfwGPCPwGFp2gigBtiYlhuBIwHS+k8C2/LbC2zzdyJidkRkIiJTXV1dQulmZpavlDBYD0yU1D/N/Z8KvAo8B5yb+kwHHk/LC9Jj0vpnI/d1RQuAunS10ShgNPByCXWZmVmR2v3lNhHxkqRHgGXAHuAVYDbwBPCwpNtS271pk3uBX0pqIHdEUJf2s1rSfHJBsge4LCKa21uXmZkVT931u0QzmUxks9lKl2Fm1m1IWhoRmULr/A5kMzNzGJiZmcPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRkOAzMzw2FgZmY4DMzMDIeBmZnhMDAzMxwGZmaGw8DMzHAYmJkZJYSBpGMl1efd/irpakk3S9qQ13563jY3SGqQ9LqkyXntU1Jbg6TrS31RZmZWnD7t3TAiXgfGA0jqDWwAfgvMAO6MiJ/m95d0PFAHnAAMB/5N0jFp9d3Al4FGYImkBRHxantrMzOz4rQ7DPZxKvDniHhLUmt9pgEPR8T7wBuSGoAJaV1DRKwDkPRw6uswMDMrk446Z1AHPJT3+HJJKyTNkTQwtY0A3s7r05jaWmvfj6SZkrKSsk1NTR1UupmZlRwGkg4CzgR+k5pmAZ8mN4W0CfhZS9cCm0cb7fs3RsyOiExEZKqrq0uq28zMPtIR00RTgWURsRmg5R5A0i+A36WHjcCRedvVABvTcmvtZmZWBh0xTXQeeVNEkoblrTsbWJWWFwB1kvpKGgWMBl4GlgCjJY1KRxl1qa+ZmZVJSUcGkvqTuwroO3nNd0gaT26q582WdRGxWtJ8cieG9wCXRURz2s/lwNNAb2BORKwupS4zMyuOIgpOz3d5mUwmstlspcswM+s2JC2NiEyhdX4HspmZOQzMzMxhYGZmOAzMzAyHgZmZ4TAwMzMcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZjgMzMwMh4GZmeEwMDMzHAZmZobDwMzMcBiYmRkOAzMzw2FgZmY4DMzMjBLCQNKxkurzbn+VdLWkQZIWSVqb7gem/pJ0l6QGSSsknZi3r+mp/1pJ0zvihZmZ2YFrdxhExOsRMT4ixgOfA3YCvwWuB56JiNHAM+kxwFRgdLrNBGYBSBoE3AScDEwAbmoJEDMzK4+OmiY6FfhzRLwFTAPmpva5wFlpeRrwQOS8CBwmaRgwGVgUEdsiYjuwCJjSQXWZmdkB6KgwqAMeSstDI2ITQLofktpHAG/nbdOY2lpr34+kmZKykrJNTU0dVLqZmZUcBpIOAs4EfvNxXQu0RRvt+zdGzI6ITERkqquriyvUzMxa1RFHBlOBZRGxOT3enKZ/SPdbUnsjcGTedjXAxjbazcysTDoiDM7joykigAVAyxVB04HH89ovTFcVTQR2pGmkp4FJkgamE8eTUpuZmZVJn1I2ltQf+DLwnbzmHwHzJV0ErAe+ltqfBE4HGshdeTQDICK2SboVWJL63RIR20qpy8zMiqOIgtPzXV4mk4lsNlvpMszMug1JSyMiU2id34FsZmYOAzMz64lhsPEV2PN+paswM+tSSjqB3O188P9g7pkgQf/BoF6Aco8/vDcz68IOHgT/+akO323PCoM+B8PX7oPV/wt2/w0IiL0QQSvvczMz61r6fbJTdtuzwqBXL/iH03I3MzP7UM87Z2BmZvtxGJiZmcPAzMwcBmZmhsPAzMxwGJiZGQ4DMzPDYWBmZnTjj7CW1AS81c7NDwe2dmA5HcV1Fcd1Faer1gVdt7Z/b3UdFREFvzO424ZBKSRlW/tM70pyXcVxXcXpqnVB162tJ9XlaSIzM3MYmJlZzw2D2ZUuoBWuqziuqzhdtS7ourX1mLp65DkDMzP7ez31yMDMzPI4DMzMrGeFgaQpkl6X1CDp+grX8qaklZLqJWVT2yBJiyStTfcDy1TLHElbJK3KaytYi3LuSmO4QtKJZa7rZkkb0rjVSzo9b90Nqa7XJU3uxLqOlPScpNckrZZ0VWqv6Ji1UVdFx0xSP0kvS1qe6vqX1D5K0ktpvOZJOii1902PG9L6kWWu635Jb+SN1/jUXraf/fR8vSW9Iul36XHnjldE9Igb0Bv4M3A0cBCwHDi+gvW8CRy+T9sdwPVp+Xrgx2WqpRY4EVj1cbUApwNPAQImAi+Vua6bge8V6Ht8+jftC4xK/9a9O6muYcCJafkQYE16/oqOWRt1VXTM0usekJargJfSOMwH6lL7PcAlaflS4J60XAfM66Txaq2u+4FzC/Qv289+er7/Avwa+F163Knj1ZOODCYADRGxLiI+AB4GplW4pn1NA+am5bnAWeV40ohYDGw7wFqmAQ9EzovAYZKGlbGu1kwDHo6I9yPiDaCB3L95Z9S1KSKWpeX3gNeAEVR4zNqoqzVlGbP0uv9veliVbgGcAjyS2vcdr5ZxfAQ4VZLKWFdryvazL6kG+E/Av6bHopPHqyeFwQjg7bzHjbT9i9LZAvi9pKWSZqa2oRGxCXK/2MCQilXXei1dYRwvT4fpc/Km0ipSVzok/yy5vyq7zJjtUxdUeMzSlEc9sAVYRO4o5N2I2FPguT+sK63fAQwuR10R0TJet6fxulNS333rKlBzR/vvwH8F9qbHg+nk8epJYVAoKSt5Xe0/RcSJwFTgMkm1FaylGJUex1nAp4HxwCbgZ6m97HVJGgA8ClwdEX9tq2uBtk6rrUBdFR+ziGiOiPFADbmjj+PaeO6K1SVpLHADMAY4CRgEXFfOuiSdAWyJiKX5zW08d4fU1ZPCoBE4Mu9xDbCxQrUQERvT/Rbgt+R+QTa3HHam+y2Vqq+NWio6jhGxOf0C7wV+wUfTGmWtS1IVuf9wH4yIx1JzxcesUF1dZcxSLe8C/4fcnPthkvoUeO4P60rrP8mBTxeWWteUNN0WEfE+cB/lH69/As6U9Ca56exTyB0pdOp49aQwWAKMTmfkDyJ3omVBJQqR9AlJh7QsA5OAVame6anbdODxStSXtFbLAuDCdGXFRGBHy9RIOewzR3s2uXFrqasuXVkxChgNvNxJNQi4F3gtIn6et6qiY9ZaXZUeM0nVkg5LywcDp5E7n/EccG7qtu94tYzjucCzkc6OlqGuP+UFusjNy+ePV6f/O0bEDRFRExEjyf0/9WxEnE9nj1dnnQnvijdyVwOsITdfeWMF6zia3FUcy4HVLbWQm+d7Blib7geVqZ6HyE0f7Cb3V8ZFrdVC7pD07jSGK4FMmev6ZXreFemXYFhe/xtTXa8DUzuxrv9I7jB8BVCfbqdXeszaqKuiYwb8B+CV9PyrgB/k/R68TO7E9W+Avqm9X3rckNYfXea6nk3jtQr4FR9dcVS2n/28Gv+Zj64m6tTx8sdRmJlZj5omMjOzVjgMzMzMYWBmZg4DMzPDYWBmZjgMzMwMh4GZmQH/Hw5bXBQp/AV7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.52173962282097"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.6638035531544"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.236502094632442e-10"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explained_variance_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a616b1e50>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,predictions)\n",
    "\n",
    "# Perfect predictions\n",
    "plt.plot(y_test,y_test,'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
